{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuq6CIrfSrbq",
        "outputId": "1e922abe-6fd7-4740-a1b9-5fd36a515d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/dataset/klasifikasi_squat/model4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKf38QknTG6Y",
        "outputId": "69021509-45d1-42eb-cfdb-048a8706485e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset/klasifikasi_squat/model4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGKPq241Ta1F",
        "outputId": "62498a42-e58f-4de2-d02b-6b6fdc845f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mexamples\u001b[0m/                     landmark_squat_train_data.csv  squat_labels.txt  weights.best.hdf5\n",
            "landmark_squat_test_data.csv  movenet_thunder.tflite         squat.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNsH6b59kQkn"
      },
      "outputs": [],
      "source": [
        "!pip install -q opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import cv2\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "04Hn1NWakvEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download model from TF Hub and check out inference code from GitHub\n",
        "!wget -q -O movenet_thunder.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/float16/4?lite-format=tflite\n",
        "!git clone https://github.com/tensorflow/examples.git\n",
        "pose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')\n",
        "sys.path.append(pose_sample_rpi_path)\n",
        "\n",
        "# Load MoveNet Thunder model\n",
        "import utils\n",
        "from data import BodyPart\n",
        "from ml import Movenet\n",
        "movenet = Movenet('movenet_thunder')\n",
        "\n",
        "# Define function to run pose estimation using MoveNet Thunder.\n",
        "# You'll apply MoveNet's cropping algorithm and run inference multiple times on\n",
        "# the input image to improve pose estimation accuracy.\n",
        "def detect(input_tensor, inference_count=3):\n",
        "  image_height, image_width, channel = input_tensor.shape\n",
        "\n",
        "  # Detect pose using the full input image\n",
        "  movenet.detect(input_tensor.numpy(), reset_crop_region=True)\n",
        "\n",
        "  # Repeatedly using previous detection result to identify the region of\n",
        "  # interest and only croping that region to improve detection accuracy\n",
        "  for _ in range(inference_count - 1):\n",
        "    person = movenet.detect(input_tensor.numpy(),\n",
        "                            reset_crop_region=False)\n",
        "\n",
        "  return person"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsLNb5GWkxI_",
        "outputId": "293f390f-8fc8-4438-e505-884ddbd1b441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'examples' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def draw_prediction_on_image(\n",
        "#     image, person, crop_region=None, close_figure=True,\n",
        "#     keep_input_size=False):\n",
        "#   # Draw the detection result on top of the image.\n",
        "#   image_np = utils.visualize(image, [person])\n",
        "\n",
        "#   # Plot the image with detection results.\n",
        "#   height, width, channel = image.shape\n",
        "#   aspect_ratio = float(width) / height\n",
        "#   fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
        "#   im = ax.imshow(image_np)\n",
        "\n",
        "#   if close_figure:\n",
        "#     plt.close(fig)\n",
        "\n",
        "#   if not keep_input_size:\n",
        "#     image_np = utils.keep_aspect_ratio_resizer(image_np, (512, 512))\n",
        "\n",
        "#   return image_np"
      ],
      "metadata": {
        "id": "Lr89PuHAURXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MoveNetPreprocessor(object):\n",
        "#   def __init__(self,\n",
        "#                images_in_folder,\n",
        "#                images_out_folder,\n",
        "#                csvs_out_path):\n",
        "\n",
        "#     self._images_in_folder = images_in_folder\n",
        "#     self._images_out_folder = images_out_folder\n",
        "#     self._csvs_out_path = csvs_out_path\n",
        "#     self._messages = []\n",
        "\n",
        "#     # Create a temp dir to store the pose CSVs per class\n",
        "#     self._csvs_out_folder_per_class = tempfile.mkdtemp()\n",
        "\n",
        "#     # Get list of pose classes and print image statistics\n",
        "#     self._pose_class_names = sorted(\n",
        "#         [n for n in os.listdir(self._images_in_folder) if not n.startswith('.')]\n",
        "#         )\n",
        "\n",
        "#   def process(self, per_pose_class_limit=None, detection_threshold=0.1):\n",
        "#     # Loop through the classes and preprocess its images\n",
        "#     for pose_class_name in self._pose_class_names:\n",
        "#       print('Preprocessing', pose_class_name, file=sys.stderr)\n",
        "\n",
        "#       # Paths for the pose class.\n",
        "#       images_in_folder = os.path.join(self._images_in_folder, pose_class_name)\n",
        "#       images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
        "#       csv_out_path = os.path.join(self._csvs_out_folder_per_class,\n",
        "#                                   pose_class_name + '.csv')\n",
        "#       if not os.path.exists(images_out_folder):\n",
        "#         os.makedirs(images_out_folder)\n",
        "\n",
        "#       # Detect landmarks in each image and write it to a CSV file\n",
        "#       with open(csv_out_path, 'w') as csv_out_file:\n",
        "#         csv_out_writer = csv.writer(csv_out_file,\n",
        "#                                     delimiter=',',\n",
        "#                                     quoting=csv.QUOTE_MINIMAL)\n",
        "#         # Get list of images\n",
        "#         image_names = sorted(\n",
        "#             [n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
        "#         if per_pose_class_limit is not None:\n",
        "#           image_names = image_names[:per_pose_class_limit]\n",
        "\n",
        "#         valid_image_count = 0\n",
        "\n",
        "#         # Detect pose landmarks from each image\n",
        "#         for image_name in tqdm.tqdm(image_names):\n",
        "#           image_path = os.path.join(images_in_folder, image_name)\n",
        "\n",
        "#           try:\n",
        "#             image = tf.io.read_file(image_path)\n",
        "#             image = tf.io.decode_jpeg(image)\n",
        "#           except:\n",
        "#             self._messages.append('Skipped ' + image_path + '. Invalid image.')\n",
        "#             continue\n",
        "#           else:\n",
        "#             image = tf.io.read_file(image_path)\n",
        "#             image = tf.io.decode_jpeg(image)\n",
        "#             image_height, image_width, channel = image.shape\n",
        "\n",
        "#           # Skip images that isn't RGB because Movenet requires RGB images\n",
        "#           if channel != 3:\n",
        "#             self._messages.append('Skipped ' + image_path +\n",
        "#                                   '. Image isn\\'t in RGB format.')\n",
        "#             continue\n",
        "#           person = detect(image)\n",
        "\n",
        "#           # Save landmarks if all landmarks were detected\n",
        "#           min_landmark_score = min(\n",
        "#               [keypoint.score for keypoint in person.keypoints])\n",
        "#           should_keep_image = min_landmark_score >= detection_threshold\n",
        "#           if not should_keep_image:\n",
        "#             self._messages.append('Skipped ' + image_path +\n",
        "#                                   '. No pose was confidentlly detected.')\n",
        "#             continue\n",
        "\n",
        "#           valid_image_count += 1\n",
        "\n",
        "#           # Draw the prediction result on top of the image for debugging later\n",
        "#           output_overlay = draw_prediction_on_image(\n",
        "#               image.numpy().astype(np.uint8), person,\n",
        "#               close_figure=True, keep_input_size=True)\n",
        "\n",
        "#           # Write detection result into an image file\n",
        "#           output_frame = cv2.cvtColor(output_overlay, cv2.COLOR_RGB2BGR)\n",
        "#           cv2.imwrite(os.path.join(images_out_folder, image_name), output_frame)\n",
        "\n",
        "#           # Get landmarks and scale it to the same size as the input image\n",
        "#           pose_landmarks = np.array(\n",
        "#               [[keypoint.coordinate.x, keypoint.coordinate.y, keypoint.score]\n",
        "#                 for keypoint in person.keypoints],\n",
        "#               dtype=np.float32)\n",
        "\n",
        "#           # Write the landmark coordinates to its per-class CSV file\n",
        "#           coordinates = pose_landmarks.flatten().astype(str).tolist()\n",
        "#           csv_out_writer.writerow([image_name] + coordinates)\n",
        "\n",
        "#         if not valid_image_count:\n",
        "#           raise RuntimeError(\n",
        "#               'No valid images found for the \"{}\" class.'\n",
        "#               .format(pose_class_name))\n",
        "\n",
        "#     # Print the error message collected during preprocessing.\n",
        "#     print('\\n'.join(self._messages))\n",
        "\n",
        "#     # Combine all per-class CSVs into a single output file\n",
        "#     all_landmarks_df = self._all_landmarks_as_dataframe()\n",
        "#     all_landmarks_df.to_csv(self._csvs_out_path, index=False)\n",
        "\n",
        "#   def class_names(self):\n",
        "#     \"\"\"List of classes found in the training dataset.\"\"\"\n",
        "#     return self._pose_class_names\n",
        "\n",
        "#   def _all_landmarks_as_dataframe(self):\n",
        "#     \"\"\"Merge all per-class CSVs into a single dataframe.\"\"\"\n",
        "#     total_df = None\n",
        "#     for class_index, class_name in enumerate(self._pose_class_names):\n",
        "#       csv_out_path = os.path.join(self._csvs_out_folder_per_class,\n",
        "#                                   class_name + '.csv')\n",
        "#       per_class_df = pd.read_csv(csv_out_path, header=None)\n",
        "\n",
        "#       # Add the labels\n",
        "#       per_class_df['class_no'] = [class_index]*len(per_class_df)\n",
        "#       per_class_df['class_name'] = [class_name]*len(per_class_df)\n",
        "\n",
        "#       # Append the folder name to the filename column (first column)\n",
        "#       per_class_df[per_class_df.columns[0]] = (os.path.join(class_name, '')\n",
        "#         + per_class_df[per_class_df.columns[0]].astype(str))\n",
        "\n",
        "#       if total_df is None:\n",
        "#         # For the first class, assign its data to the total dataframe\n",
        "#         total_df = per_class_df\n",
        "#       else:\n",
        "#         # Concatenate each class's data into the total dataframe\n",
        "#         total_df = pd.concat([total_df, per_class_df], axis=0)\n",
        "\n",
        "#     list_name = [[bodypart.name + '_x', bodypart.name + '_y',\n",
        "#                   bodypart.name + '_score'] for bodypart in BodyPart]\n",
        "#     header_name = []\n",
        "#     for columns_name in list_name:\n",
        "#       header_name += columns_name\n",
        "#     header_name = ['file_name'] + header_name\n",
        "#     header_map = {total_df.columns[i]: header_name[i]\n",
        "#                   for i in range(len(header_name))}\n",
        "\n",
        "#     total_df.rename(header_map, axis=1, inplace=True)\n",
        "\n",
        "#     return total_df"
      ],
      "metadata": {
        "id": "6ioAZOEhUVFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MovenetLayer(tf.keras.layers.Layer):\n",
        "#     def __init__(self, model_path, **kwargs):\n",
        "#         super(MovenetLayer, self).__init__(**kwargs)\n",
        "#         self.model_path = model_path\n",
        "#         self.interpreter = tf.lite.Interpreter(model_path=self.model_path)\n",
        "#         self.interpreter.allocate_tensors()\n",
        "#         self.input_details = self.interpreter.get_input_details()\n",
        "#         self.output_details = self.interpreter.get_output_details()\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         # Resize and normalize inputs\n",
        "#         resized_inputs = tf.image.resize(inputs, (256, 256))\n",
        "#         input_tensor = tf.cast(resized_inputs, dtype=tf.uint8)  # Convert to UINT8\n",
        "#         input_tensor = (tf.cast(input_tensor, dtype=tf.float32) - 127.5) / 127.5  # Normalize to [-1, 1]\n",
        "#         input_tensor = tf.expand_dims(input_tensor, axis=0)  # Add batch dimension\n",
        "\n",
        "#         # Convert to numpy array within the tf.py_function\n",
        "#         keypoints = tf.py_function(self.get_keypoints, [input_tensor], tf.float32)\n",
        "#         keypoints.set_shape([1, 17, 3])  # Set the shape explicitly to [batch_size, num_keypoints, 3]\n",
        "#         return keypoints\n",
        "\n",
        "#     @tf.function\n",
        "#     def get_keypoints(self, input_tensor):\n",
        "#         input_tensor_uint8 = np.uint8(input_tensor_numpy)  # Convert to UINT8\n",
        "#         input_tensor = tf.cast(tf.expand_dims(image, axis=0), dtype=tf.uint8)\n",
        "\n",
        "#         # Set tensor input for interpreter (expecting UINT8)\n",
        "#         self.interpreter.set_tensor(self.input_details[0]['index'], input_tensor_uint8)\n",
        "#         self.interpreter.invoke()\n",
        "\n",
        "#         # Get output keypoints from interpreter\n",
        "#         keypoints_with_scores = self.interpreter.get_tensor(self.output_details[0]['index'])\n",
        "#         return keypoints_with_scores  # Return keypoints with scores\n"
      ],
      "metadata": {
        "id": "cbXJXqKMrem2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load CSVs preprocessed ke TRAIN dan TEST dataset."
      ],
      "metadata": {
        "id": "7aGkMcxWxAXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csvs_out_test_path = 'landmark_squat_test_data.csv'\n",
        "csvs_out_train_path = 'landmark_squat_train_data.csv'\n",
        "\n",
        "\n",
        "def load_pose_landmarks(csv_path):\n",
        "  # Load the CSV file\n",
        "  dataframe = pd.read_csv(csv_path)\n",
        "  df_to_process = dataframe.copy()\n",
        "\n",
        "  # Drop the file_name columns as you don't need it during training.\n",
        "  df_to_process.drop(columns=['file_name'], inplace=True)\n",
        "\n",
        "  # Extract the list of class names\n",
        "  classes = df_to_process.pop('class_name').unique()\n",
        "\n",
        "  # Extract the labels\n",
        "  y = df_to_process.pop('class_no')\n",
        "\n",
        "  # Convert the input features and labels into the correct format for training.\n",
        "  X = df_to_process.astype('float64')\n",
        "\n",
        "  return X, y, classes, dataframe"
      ],
      "metadata": {
        "id": "C6NH3WC0xBY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# csvs_out_test_path = 'landmark_squat_test_data.csv'\n",
        "# csvs_out_train_path = 'landmark_squat_train_data.csv'\n",
        "\n",
        "\n",
        "# def load_pose_landmarks(csv_path):\n",
        "#   # Load the CSV file\n",
        "#   dataframe = pd.read_csv(csv_path)\n",
        "#   df_to_process = dataframe.copy()\n",
        "\n",
        "#   # Drop the file_name columns as you don't need it during training.\n",
        "#   df_to_process.drop(columns=['file_name'], inplace=True)\n",
        "\n",
        "#   # Extract the list of class names\n",
        "#   classes = df_to_process.pop('class_name').unique()\n",
        "\n",
        "#   # Extract the labels\n",
        "#   y = df_to_process.pop('class_no')\n",
        "\n",
        "#   # Convert the input features and labels into the correct format for training.\n",
        "#   X = df_to_process.astype('float64')\n",
        "#   y = keras.utils.to_categorical(y)\n",
        "\n",
        "#   return X, y, classes, dataframe"
      ],
      "metadata": {
        "id": "hKRlvuyfGhU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the train data\n",
        "X, y, class_names, _ = load_pose_landmarks(csvs_out_train_path)\n",
        "\n",
        "# Split training data (X, y) into (X_train, y_train) and (X_val, y_val)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
        "                                                  test_size=0.15)"
      ],
      "metadata": {
        "id": "5rKrvZZ_xN8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "X_test, y_test, _, df_test = load_pose_landmarks(csvs_out_test_path)"
      ],
      "metadata": {
        "id": "fbUSYA0cxSXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define functions to convert the pose landmarks to a pose embedding (a.k.a. feature vector) for pose classification"
      ],
      "metadata": {
        "id": "LezOFn0I3Xwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
        "  left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
        "  right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
        "  center = left * 0.5 + right * 0.5\n",
        "  return center\n",
        "\n",
        "\n",
        "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
        "  # Hips center\n",
        "  hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP,\n",
        "                                 BodyPart.RIGHT_HIP)\n",
        "\n",
        "  # Shoulders center\n",
        "  shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
        "                                      BodyPart.RIGHT_SHOULDER)\n",
        "\n",
        "  # Torso size as the minimum body size\n",
        "  torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
        "\n",
        "  # Pose center\n",
        "  pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP,\n",
        "                                     BodyPart.RIGHT_HIP)\n",
        "  pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
        "  # Broadcast the pose center to the same size as the landmark vector to\n",
        "  # perform substraction\n",
        "  pose_center_new = tf.broadcast_to(pose_center_new,\n",
        "                                    [tf.size(landmarks) // (17*2), 17, 2])\n",
        "\n",
        "  # Dist to pose center\n",
        "  d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
        "                name=\"dist_to_pose_center\")\n",
        "  # Max dist to pose center\n",
        "  max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
        "\n",
        "  # Normalize scale\n",
        "  pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
        "\n",
        "  return pose_size\n",
        "\n",
        "\n",
        "def normalize_pose_landmarks(landmarks):\n",
        "  # Move landmarks so that the pose center becomes (0,0)\n",
        "  pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP,\n",
        "                                 BodyPart.RIGHT_HIP)\n",
        "  pose_center = tf.expand_dims(pose_center, axis=1)\n",
        "  # Broadcast the pose center to the same size as the landmark vector to perform\n",
        "  # substraction\n",
        "  pose_center = tf.broadcast_to(pose_center,\n",
        "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
        "  landmarks = landmarks - pose_center\n",
        "\n",
        "  # Scale the landmarks to a constant pose size\n",
        "  pose_size = get_pose_size(landmarks)\n",
        "  landmarks /= pose_size\n",
        "\n",
        "  return landmarks\n",
        "\n",
        "\n",
        "def landmarks_to_embedding(landmarks_and_scores):\n",
        "  # Reshape the flat input into a matrix with shape=(17, 3)\n",
        "  reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
        "\n",
        "  # Normalize landmarks 2D\n",
        "  landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
        "\n",
        "  # Flatten the normalized landmark coordinates into a vector\n",
        "  embedding = keras.layers.Flatten()(landmarks)\n",
        "\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "L0z82aew3U7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model"
      ],
      "metadata": {
        "id": "9lie1mjk3o_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "inputs = tf.keras.Input(shape=(51))\n",
        "embedding = landmarks_to_embedding(inputs)\n",
        "\n",
        "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(embedding)\n",
        "layer = keras.layers.Dropout(0.5)(layer)\n",
        "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
        "layer = keras.layers.Dropout(0.5)(layer)\n",
        "layer = keras.layers.Dense(32, activation=tf.nn.relu6)(layer)\n",
        "layer = keras.layers.Dropout(0.5)(layer)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(layer)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5fgcOiQ43nYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926860e6-212c-4a9f-9a4f-bdb8ce31fd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 51)]                 0         []                            \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 17, 3)                0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (  (None, 17, 2)                0         ['reshape[0][0]']             \n",
            " SlicingOpLambda)                                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather (TFOpL  (None, 2)                    0         ['tf.__operators__.getitem[0][\n",
            " ambda)                                                             0]']                          \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_1 (TFO  (None, 2)                    0         ['tf.__operators__.getitem[0][\n",
            " pLambda)                                                           0]']                          \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLamb  (None, 2)                    0         ['tf.compat.v1.gather[0][0]'] \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLa  (None, 2)                    0         ['tf.compat.v1.gather_1[0][0]'\n",
            " mbda)                                                              ]                             \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 2)                    0         ['tf.math.multiply[0][0]',    \n",
            " Lambda)                                                             'tf.math.multiply_1[0][0]']  \n",
            "                                                                                                  \n",
            " tf.compat.v1.size (TFOpLam  ()                           0         ['tf.__operators__.getitem[0][\n",
            " bda)                                                               0]']                          \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda  (None, 1, 2)                 0         ['tf.__operators__.add[0][0]']\n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.compat.v1.floor_div (TF  ()                           0         ['tf.compat.v1.size[0][0]']   \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.broadcast_to (TFOpLambd  (None, 17, 2)                0         ['tf.expand_dims[0][0]',      \n",
            " a)                                                                  'tf.compat.v1.floor_div[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLamb  (None, 17, 2)                0         ['tf.__operators__.getitem[0][\n",
            " da)                                                                0]',                          \n",
            "                                                                     'tf.broadcast_to[0][0]']     \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_6 (TFO  (None, 2)                    0         ['tf.math.subtract[0][0]']    \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_7 (TFO  (None, 2)                    0         ['tf.math.subtract[0][0]']    \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.multiply_6 (TFOpLa  (None, 2)                    0         ['tf.compat.v1.gather_6[0][0]'\n",
            " mbda)                                                              ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLa  (None, 2)                    0         ['tf.compat.v1.gather_7[0][0]'\n",
            " mbda)                                                              ]                             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  (None, 2)                    0         ['tf.math.multiply_6[0][0]',  \n",
            " OpLambda)                                                           'tf.math.multiply_7[0][0]']  \n",
            "                                                                                                  \n",
            " tf.compat.v1.size_1 (TFOpL  ()                           0         ['tf.math.subtract[0][0]']    \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_4 (TFO  (None, 2)                    0         ['tf.math.subtract[0][0]']    \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_5 (TFO  (None, 2)                    0         ['tf.math.subtract[0][0]']    \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_2 (TFO  (None, 2)                    0         ['tf.math.subtract[0][0]']    \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_3 (TFO  (None, 2)                    0         ['tf.math.subtract[0][0]']    \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLamb  (None, 1, 2)                 0         ['tf.__operators__.add_3[0][0]\n",
            " da)                                                                ']                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.floor_div_1 (  ()                           0         ['tf.compat.v1.size_1[0][0]'] \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLa  (None, 2)                    0         ['tf.compat.v1.gather_4[0][0]'\n",
            " mbda)                                                              ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLa  (None, 2)                    0         ['tf.compat.v1.gather_5[0][0]'\n",
            " mbda)                                                              ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLa  (None, 2)                    0         ['tf.compat.v1.gather_2[0][0]'\n",
            " mbda)                                                              ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLa  (None, 2)                    0         ['tf.compat.v1.gather_3[0][0]'\n",
            " mbda)                                                              ]                             \n",
            "                                                                                                  \n",
            " tf.broadcast_to_1 (TFOpLam  (None, 17, 2)                0         ['tf.expand_dims_1[0][0]',    \n",
            " bda)                                                                'tf.compat.v1.floor_div_1[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TF  (None, 2)                    0         ['tf.math.multiply_4[0][0]',  \n",
            " OpLambda)                                                           'tf.math.multiply_5[0][0]']  \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (None, 2)                    0         ['tf.math.multiply_2[0][0]',  \n",
            " OpLambda)                                                           'tf.math.multiply_3[0][0]']  \n",
            "                                                                                                  \n",
            " tf.math.subtract_2 (TFOpLa  (None, 17, 2)                0         ['tf.math.subtract[0][0]',    \n",
            " mbda)                                                               'tf.broadcast_to_1[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLa  (None, 2)                    0         ['tf.__operators__.add_2[0][0]\n",
            " mbda)                                                              ',                            \n",
            "                                                                     'tf.__operators__.add_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_8 (TFO  (17, 2)                      0         ['tf.math.subtract_2[0][0]']  \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.compat.v1.norm (TFOpLam  ()                           0         ['tf.math.subtract_1[0][0]']  \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.norm_1 (TFOpL  (2,)                         0         ['tf.compat.v1.gather_8[0][0]'\n",
            " ambda)                                                             ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLa  ()                           0         ['tf.compat.v1.norm[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLa  ()                           0         ['tf.compat.v1.norm_1[0][0]'] \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.maximum (TFOpLambd  ()                           0         ['tf.math.multiply_8[0][0]',  \n",
            " a)                                                                  'tf.math.reduce_max[0][0]']  \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambd  (None, 17, 2)                0         ['tf.math.subtract[0][0]',    \n",
            " a)                                                                  'tf.math.maximum[0][0]']     \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 34)                   0         ['tf.math.truediv[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  4480      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   8256      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 64)                   0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 32)                   2080      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 32)                   0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    33        ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14849 (58.00 KB)\n",
            "Trainable params: 14849 (58.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Add a checkpoint callback to store the checkpoint that has the highest\n",
        "# validation accuracy.\n",
        "checkpoint_path = \"weights.best.hdf5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='max')\n",
        "earlystopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
        "                                              patience=10)\n",
        "\n",
        "# Start training\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=200,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint, earlystopping])"
      ],
      "metadata": {
        "id": "ITDbV28Y3sSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0f3673-8609-48cf-d311-ee058ed4c60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.6881 - accuracy: 0.5477\n",
            "Epoch 1: val_accuracy improved from -inf to 0.91603, saving model to weights.best.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 4s 53ms/step - loss: 0.6861 - accuracy: 0.5575 - val_loss: 0.6617 - val_accuracy: 0.9160\n",
            "Epoch 2/200\n",
            "12/24 [==============>...............] - ETA: 0s - loss: 0.6575 - accuracy: 0.7500\n",
            "Epoch 2: val_accuracy improved from 0.91603 to 0.95420, saving model to weights.best.hdf5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.6395 - accuracy: 0.7848 - val_loss: 0.5711 - val_accuracy: 0.9542\n",
            "Epoch 3/200\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.5629 - accuracy: 0.8574\n",
            "Epoch 3: val_accuracy improved from 0.95420 to 0.99237, saving model to weights.best.hdf5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.5437 - accuracy: 0.8579 - val_loss: 0.3901 - val_accuracy: 0.9924\n",
            "Epoch 4/200\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.3813 - accuracy: 0.9375\n",
            "Epoch 4: val_accuracy did not improve from 0.99237\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.9432 - val_loss: 0.1914 - val_accuracy: 0.9924\n",
            "Epoch 5/200\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.2288 - accuracy: 0.9444\n",
            "Epoch 5: val_accuracy did not improve from 0.99237\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.2233 - accuracy: 0.9459 - val_loss: 0.1054 - val_accuracy: 0.9924\n",
            "Epoch 6/200\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.1603 - accuracy: 0.9609\n",
            "Epoch 6: val_accuracy did not improve from 0.99237\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.1564 - accuracy: 0.9621 - val_loss: 0.0585 - val_accuracy: 0.9924\n",
            "Epoch 7/200\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.1093 - accuracy: 0.9812\n",
            "Epoch 7: val_accuracy did not improve from 0.99237\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9824 - val_loss: 0.0490 - val_accuracy: 0.9847\n",
            "Epoch 8/200\n",
            "14/24 [================>.............] - ETA: 0s - loss: 0.0742 - accuracy: 0.9866\n",
            "Epoch 8: val_accuracy improved from 0.99237 to 1.00000, saving model to weights.best.hdf5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.1012 - accuracy: 0.9811 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "14/24 [================>.............] - ETA: 0s - loss: 0.1091 - accuracy: 0.9754\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9838 - val_loss: 0.0280 - val_accuracy: 0.9924\n",
            "Epoch 10/200\n",
            "15/24 [=================>............] - ETA: 0s - loss: 0.0808 - accuracy: 0.9812\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9811 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0933 - accuracy: 0.9792\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.9783 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0592 - accuracy: 0.9934\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9905 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0903 - accuracy: 0.9844\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9865 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0714 - accuracy: 0.9863\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0621 - accuracy: 0.9892 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0585 - accuracy: 0.9918\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9905 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0697 - accuracy: 0.9901\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9919 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0537 - accuracy: 0.9891\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0569 - accuracy: 0.9878 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0617 - accuracy: 0.9883\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9865 - val_loss: 0.0093 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning curves\n",
        "def plot_learning_curve(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot the learning curves\n",
        "plot_learning_curve(history)"
      ],
      "metadata": {
        "id": "j08a9MF-Gf_i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "4a0965eb-6226-4f64-e49e-0b09956825f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the TEST dataset\n",
        "loss, accuracy = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "Pu5aM-kX3x0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cbd7fe-8a99-463d-ba6c-8cec982628f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot confusion matrix\n",
        "# def plot_confusion_matrix(cm, classes,\n",
        "#                           normalize=False,\n",
        "#                           title='Confusion matrix',\n",
        "#                           cmap=plt.cm.Blues):\n",
        "#     \"\"\"Plots the confusion matrix.\"\"\"\n",
        "#     if normalize:\n",
        "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#         print(\"Normalized confusion matrix\")\n",
        "#     else:\n",
        "#         print('Confusion matrix, without normalization')\n",
        "\n",
        "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "#     plt.title(title)\n",
        "#     plt.colorbar()\n",
        "#     tick_marks = np.arange(len(classes))\n",
        "#     plt.xticks(tick_marks, classes, rotation=45)\n",
        "#     plt.yticks(tick_marks, classes)\n",
        "\n",
        "#     fmt = '.2f' if normalize else 'd'\n",
        "#     thresh = cm.max() / 2.\n",
        "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "#         plt.text(j, i, format(cm[i, j], fmt),\n",
        "#                  horizontalalignment=\"center\",\n",
        "#                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "#     plt.ylabel('True label')\n",
        "#     plt.xlabel('Predicted label')\n",
        "#     plt.tight_layout()\n",
        "\n",
        "# # Plot non-normalized confusion matrix\n",
        "# plt.figure()\n",
        "# plot_confusion_matrix(cm, classes=class_names, title='Confusion Matrix of Pose Classification Model')\n",
        "\n",
        "# # Print classification report\n",
        "# print('\\nClassification Report:\\n', classification_report(y_test, y_pred_label, target_names=class_names))"
      ],
      "metadata": {
        "id": "xT75C1n6HJk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def plot_confusion_matrix(cm, classes,\n",
        "#                           normalize=False,\n",
        "#                           title='Confusion matrix',\n",
        "#                           cmap=plt.cm.Blues):\n",
        "#   \"\"\"Plots the confusion matrix.\"\"\"\n",
        "#   if normalize:\n",
        "#     cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#     print(\"Normalized confusion matrix\")\n",
        "#   else:\n",
        "#     print('Confusion matrix, without normalization')\n",
        "\n",
        "#   plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "#   plt.title(title)\n",
        "#   plt.colorbar()\n",
        "#   tick_marks = np.arange(len(classes))\n",
        "#   plt.xticks(tick_marks, classes, rotation=55)\n",
        "#   plt.yticks(tick_marks, classes)\n",
        "#   fmt = '.2f' if normalize else 'd'\n",
        "#   thresh = cm.max() / 2.\n",
        "#   for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "#     plt.text(j, i, format(cm[i, j], fmt),\n",
        "#               horizontalalignment=\"center\",\n",
        "#               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "#   plt.ylabel('True label')\n",
        "#   plt.xlabel('Predicted label')\n",
        "#   plt.tight_layout()\n",
        "\n",
        "# # Classify pose in the TEST dataset using the trained model\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Convert the prediction result to class name\n",
        "# y_pred_label = [class_names[i] for i in np.argmax(y_pred, axis=1)]\n",
        "# y_true_label = [class_names[i] for i in np.argmax(y_test, axis=1)]\n",
        "\n",
        "# # Plot the confusion matrix\n",
        "# cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "# plot_confusion_matrix(cm,\n",
        "#                       class_names,\n",
        "#                       title ='Confusion Matrix of Pose Classification Model')\n",
        "\n",
        "# # Print the classification report\n",
        "# print('\\nClassification Report:\\n', classification_report(y_true_label,\n",
        "#                                                           y_pred_label))"
      ],
      "metadata": {
        "id": "7MKvoA-HK6xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert the pose classification model to TensorFlow Lite"
      ],
      "metadata": {
        "id": "tSigfYLZzqHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "print('Model size: %dKB' % (len(tflite_model) / 1024))\n",
        "\n",
        "with open('squat.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "FDl0T5bfzhn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93a74c2-bfeb-463d-a0b4-81f00c4f6dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 28KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('squat_labels.txt', 'w') as f:\n",
        "  f.write('\\n'.join(class_names))"
      ],
      "metadata": {
        "id": "26ueBxg2zsfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def evaluate_model(interpreter, X, y_true):\n",
        "#   \"\"\"Evaluates the given TFLite model and return its accuracy.\"\"\"\n",
        "#   input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "#   output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "#   # Run predictions on all given poses.\n",
        "#   y_pred = []\n",
        "#   for i in range(len(y_true)):\n",
        "#     # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "#     # the model's input data format.\n",
        "#     test_image = X[i: i + 1].astype('float32')\n",
        "#     interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "#     # Run inference.\n",
        "#     interpreter.invoke()\n",
        "\n",
        "#     # Post-processing: remove batch dimension and find the class with highest\n",
        "#     # probability.\n",
        "#     output = interpreter.tensor(output_index)\n",
        "#     predicted_label = np.argmax(output()[0])\n",
        "#     y_pred.append(predicted_label)\n",
        "\n",
        "#   # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "#   y_pred = keras.utils.to_categorical(y_pred)\n",
        "#   return accuracy_score(y_true, y_pred)\n",
        "\n",
        "# # Evaluate the accuracy of the converted TFLite model\n",
        "# classifier_interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "# classifier_interpreter.allocate_tensors()\n",
        "# print('Accuracy of TFLite model: %s' %\n",
        "#       evaluate_model(classifier_interpreter, X_test, y_test))"
      ],
      "metadata": {
        "id": "HC7FmZtnz4uX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26eab542-7e6e-4e53-fc45-852a7518ef1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of TFLite model: 0.45754716981132076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install TensorFlow Lite Metadata Writer"
      ],
      "metadata": {
        "id": "uXNWTZh3d5XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite-support"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARHulq0jd65H",
        "outputId": "f173527b-94d6-45eb-9b5f-ee1cdbcb391b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tflite-support in /usr/local/lib/python3.10/dist-packages (0.4.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (1.25.2)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (24.3.25)\n",
            "Requirement already satisfied: protobuf<4,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (0.4.7)\n",
            "Requirement already satisfied: pybind11>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (2.12.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite-support) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import metadata_info"
      ],
      "metadata": {
        "id": "Z004ddZXeoRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths for the TFLite model and the metadata output\n",
        "model_path = 'squat.tflite'\n",
        "model_with_metadata_path = 'squat_with_metadata.tflite'\n",
        "label_file = 'squat_labels.txt'\n",
        "\n",
        "# Create the ImageClassifierWriter\n",
        "writer = image_classifier.MetadataWriter.create_for_inference(\n",
        "    writer_utils.load_file(model_path),\n",
        "    input_norm_mean=[127.5],\n",
        "    input_norm_std=[127.5],\n",
        "    label_file_paths=[label_file]\n",
        ")\n",
        "\n",
        "# Populate the metadata buffer\n",
        "metadata_buf = writer.populate()\n",
        "\n",
        "# Save the metadata to the model\n",
        "# First save the original model bytes\n",
        "with open(model_with_metadata_path, 'wb') as f:\n",
        "    f.write(writer_utils.load_file(model_path))\n",
        "\n",
        "# Then attach the metadata to the model\n",
        "# Using writer_utils to update the model file\n",
        "model_with_metadata = writer_utils.load_file(model_with_metadata_path)\n",
        "with open(model_with_metadata_path, 'wb') as f:\n",
        "    f.write(model_with_metadata + metadata_buf)\n",
        "\n",
        "print(\"Metadata added to the model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt638Aa4d8uP",
        "outputId": "a7a0eced-66ff-4bb4-9cf9-d5461454a1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata added to the model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6QMcIDf97sMp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}